**SUPERVISED LEARNING IN ONCOLOGICAL STUDIES**

**Introduction**

Machine learning (ML) has the power to transform oncology and medicine in general (Rajkomar et al., 2019) The introduction of ML in health care has been made possible by the digitization of patient data, using electronic medical records (EMRs). This change offers a unique chance to gain clinical insights from large-scale analysis of patient data, leading to a more personalized approach to medicine that considers each patient's specific characteristics

**Methodologies**

ML covers a wide range of methods (Hastie et al., 2009). Supervised learning predicts a known outcome, such as the presence of a tumour, survival length, or response to treatment. Unsupervised learning finds patterns and sub-groups within data, often not for prediction purposes, but for exploratory analysis. Reinforcement learning is used for making decisions over time by learning a strategy from data, which is useful in determining the best treatment plans for cancer patients (Yu et al., 2019) (Padmanabhan et al., 2017).

**Supervised Learning Approaches**

<!--[if !supportLists]-->Ø  <!--[endif]-->**Linear models.**

With a straight-line equation, Linear models connect independent variables with the outcome of interest. Linear regression assumes that the outcome is directly related to the feature values with an additive relationship between features. Other form of regression models, such as logistic regression (for binary classification), similarly assume an additive relationship but apply a transformation of the linear function according to the prediction task.

<!--[if !supportLists]-->Ø  <!--[endif]-->**Decision tree models.**

Classification and regression trees were introduced by Leo Breiman as a substitute to linear models (Breiman et al., 2017). A decision tree divides observations into subgroups based on feature splits, ending in leaves that contain these subgroups. The final tree partitions the population; every observation is assigned to a single leaf based on the feature splits. A single prediction is generated for each leaf. In classification tasks, this prediction is typically a probability calculated from the most common outcome in the leaf, while in continuous outcomes, it is usually the average outcome value in the leaf.****

<!--[if !supportLists]-->Ø  <!--[endif]-->**Neural networks.  **

Neural networks (NN) link features to predicted outcomes using a layered network of mathematical operations. The model first maps input features to nodes in a hidden layer through linear functions, then connects these nodes to an outcome using a nonlinear activation function. This setup allows neural networks to understand complex interactions between features and the outcome. Advancements in the field of NN include the introduction of recurrent neural networks, convolutional neural networks, and generative adversarial networks (Schmidhuber, 2015).

 

 

 

 

**REFERENCES**

Breiman, L., Friedman, J. H., Olshen, R. A., & Stone, C. J. (2017). Classification and regression trees. _Classification and Regression Trees_, 1–358. https\://doi.org/10.1201/9781315139470/CLASSIFICATION-REGRESSION-TREES-LEO-BREIMAN-JEROME-FRIEDMAN-OLSHEN-CHARLES-STONE/ACCESSIBILITY-INFORMATION

Hastie, T., Tibshirani, R., & Friedman, J. (2009). _The Elements of Statistical Learning_. https\://doi.org/10.1007/978-0-387-84858-7

Padmanabhan, R., Meskin, N., & Haddad, W. M. (2017). Reinforcement learning-based control of drug dosing for cancer chemotherapy treatment. _Mathematical Biosciences_, _293_, 11–20. https\://doi.org/10.1016/J.MBS.2017.08.004

Rajkomar, A., Dean, J., & Kohane, I. (2019). Machine Learning in Medicine. _The New England Journal of Medicine_, _380_(14), 1347–1358. https\://doi.org/10.1056/NEJMRA1814259

Schmidhuber, J. (2015). Deep learning in neural networks: An overview. _Neural Networks_, _61_, 85–117. https\://doi.org/10.1016/J.NEUNET.2014.09.003

Yu, C., Liu, J., Nemati, S., & Yin, G. (2019). Reinforcement Learning in Healthcare: A Survey. _ACM Computing Surveys_, _55_(1). https\://doi.org/10.1145/3477600

 ****

 
